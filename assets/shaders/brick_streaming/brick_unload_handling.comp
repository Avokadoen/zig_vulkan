#version 450

#extension GL_EXT_debug_printf : disable
// debugPrintfEXT("hello world %f", 1.0);

#include "../raytracing/ray_commons.glsl"

layout(local_size_x_id = 0, local_size_y = 1, local_size_z = 1) in;

// TODO: dont care about brick set for this
layout (std430, set = 0, binding = 0) readonly buffer BrickSetBuffer {
    uint brick_set_bits[];
};
layout (std430, set = 0, binding = 1) buffer BrickIndex {
    uint brick_index_req_count_status[];
};
layout (std430, set = 0, binding = 2) buffer BrickBuffer {
    Brick bricks[];
};

layout (std430, set = 1, binding = 0) buffer BrickRequestLimits {
    BrickLimits brick_limits;
};
layout (std430, set = 2, binding = 0) readonly buffer BrickUnloadRequestIndices {
    uint unload_request_brick_indices[];
};
layout (std430, set = 3, binding = 0) buffer BrickIndexToBrickIndicesIndex {
    uint brick_index_to_brick_indices_index[];
};

layout (std430, set = 4, binding = 0) readonly buffer MaterialBuffer {
    Material materials[]; // TODO: We dont need this binding
};
layout (std430, set = 4, binding = 1) buffer MaterialIndexBuffer {
    uint material_indices_8b[];
};

void main() {
    const uint unload_request_index = gl_GlobalInvocationID.x;
    if (unload_request_index >= brick_limits.unload_request_count) {
        return;
    }

    if (brick_limits.active_bricks <= 0) {
        return;
    }

    // We perform a swap remove to unload brick. 
    // This means we grab the last active brick and swap this the index requested to be removed
    uint remove_index = unload_request_brick_indices[unload_request_index];
    
    const uint deleted_index_bits = brick_index_req_count_status[remove_index];
    {
        const uint deleted_index_status = bitfieldExtract(
            deleted_index_bits,
            BRICK_STATUS_OFFSET,
            BRICK_STATUS_BITS
        );

        // In some scenarios the host might request a unloading of a unloaded brick.
        // We should ignore these requests
        if (deleted_index_status != BRICK_STATUS_UNLOADING && deleted_index_status != BRICK_STATUS_LOADED) {
            return;
        }
    }

    // Index is no longer active
    brick_index_req_count_status[remove_index] = bitfieldInsert(
        deleted_index_bits,
        BRICK_STATUS_UNLOADED,
        BRICK_STATUS_OFFSET,
        BRICK_STATUS_BITS
    );

    const uint inactive_brick_index = bitfieldExtract(
        deleted_index_bits,
        BRICK_INDEX_OFFSET,
        BRICK_INDEX_BITS
    );

    const int removed_brick_index = atomicAdd(brick_limits.active_bricks, -1) - 1;
    if (removed_brick_index <= 0) {
        return;
    }

    // move the brick in delete slot to its new location
    bricks[inactive_brick_index] = bricks[removed_brick_index];

    {
        // TODO: not 512 if we have varying material indices size (buckets)
        // move the material indices
        const uint material_index_count = 512 / 4;
        const uint inactive_start_index = inactive_brick_index * material_index_count;
        const uint remove_start_index = removed_brick_index * material_index_count; 
        for (uint voxel_index_4 = 0; voxel_index_4 < material_index_count; voxel_index_4++) {
            material_indices_8b[inactive_start_index + voxel_index_4] = material_indices_8b[remove_start_index + voxel_index_4];
        }
    }

    // map a brick index to a index to the index buffer 
    const uint brick_index_index = brick_index_to_brick_indices_index[removed_brick_index];
    brick_index_to_brick_indices_index[inactive_brick_index] = brick_index_index;

    brick_index_req_count_status[brick_index_index] = bitfieldInsert(
        brick_index_req_count_status[brick_index_index],
        inactive_brick_index,
        BRICK_INDEX_OFFSET,
        BRICK_INDEX_BITS
    );
}

